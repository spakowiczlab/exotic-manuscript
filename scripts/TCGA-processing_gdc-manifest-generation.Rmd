---
title: "gdc-manifest-generation"
author: "Rebecca Hoyd"
date: "February 27, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(GenomicDataCommons)
```

# Look for variables to filter

```{r, eval=F}
avail.data <- available_fields(files())
length(avail.data)

```

```{r}
test[grep("file_id", test)]
```


```{r, eval=F}
avail.data[grep("project", avail.data)]
```

```{r, eval=F}
avail.data[grep("tumor", avail.data)]
```

# Query the files, find desired filters

```{r, eval=F}
# Get the files from TCGA only that are of the data type "aligned reads"
tcga.bams <- GenomicDataCommons::files(legacy = F) %>%
  filter(type == "aligned_reads") %>%
  # filter(experimental_strategy == "RNA-Seq") %>% # This line breaks everything after it but the results, but I want                                                         to add it back later
  filter(cases.project.program.name =='TCGA')

# Use facet + aggregations to count how many files are in each value of a given variable
tcga.bams %>%
  # facet(c("cases.project.name", "cases.project.project_id")) %>% 
  facet(c("cases.project.project_id")) %>% 
  aggregations()
```

```{r, eval=F}
tcga.bams %>%
  # facet(c("cases.project.name", "cases.project.project_id")) %>% 
  facet(c("experimental_strategy")) %>% 
  aggregations()

tcga.bams %>%
  # facet(c("cases.project.name", "cases.project.project_id")) %>% 
  facet(c('cases.samples.sample_type')) %>% 
  aggregations()
```

# Get the list of files, limited to desired cancers + made into manifest

```{r, eval=F}
grab.uids.1 <- list()
for(c in c("TCGA-LUAD", "TCGA-COAD", "TCGA-READ")){
  grab.uids.1[[c]] <- tcga.bams %>%
  filter(cases.samples.sample_type == "primary tumor") %>%
  filter(experimental_strategy == "RNA-Seq") %>%
  filter(cases.project.project_id == c) %>% 
  manifest() %>%
  dplyr::mutate(cancer = c,
                source = "tumor")
}
grab.uids.1 <- dplyr::bind_rows(grab.uids.1)
nrow(grab.uids.1)

grab.uids.2 <- list()
for(c in c("TCGA-LUAD", "TCGA-COAD", "TCGA-READ")){
  grab.uids.2[[c]] <- tcga.bams %>%
  filter(cases.samples.sample_type == "solid tissue normal") %>%
  filter(experimental_strategy == "RNA-Seq") %>%
  filter(cases.project.project_id == c) %>% 
  manifest() %>%
  dplyr::mutate(cancer = c,
                source = "solid.tissue.normal")
}
grab.uids.2 <- dplyr::bind_rows(grab.uids.2)
nrow(grab.uids.2)

grab.uids <- dplyr::bind_rows(grab.uids.1, grab.uids.2)
```

```{r}
grab.clinid <- GenomicDataCommons::cases(legacy = F) %>%
  GenomicDataCommons::select(c(default_fields("cases"), "files.file_id")) %>%
  filter(files.type == "aligned_reads") %>%
  filter(project.program.name =='TCGA') %>%
  filter(samples.sample_type == "primary tumor") %>%
  # filter(files.experimental_strategy == "RNA-Seq") %>%
  filter(project.project_id == "TCGA-COAD") %>%
  response_all()

for(cid in names(grab.clinid$results$files)){
  grab.clinid$results$files[[cid]] <- grab.clinid$results$files[[cid]] %>%
    dplyr::mutate(case_id = cid)
}
checkfilepres <- dplyr::bind_rows(grab.clinid$results$files)
any(checkfilepres$file_id %in% grab.uids$id)
```

```{r}
# We need to keep the manifest, as it has all the metadata of where the samples are from, and we should date it because TCGA can change as more studies are updated
# write.csv(grab.uids, "../data/tcga-gdc-manifest_2020-03-11.csv", row.names = F)
```

# Notes on next steps

The following function downloads files based on the uuids provided, and automatically throws them in a cache. This is the step that requires Dan's token.

```{r, eval = F}
fnames = gdcdata(grab.uids$id[1],progress=FALSE, token = tok)
```


After this, we will need to make the BAM files fastqs again. It looks like each row of the manifest I generated is referring to a single BAM file, which does simplify things, however I need a way to detect whether the BAM was created from single or paired end reads. We probably only want to continue with files that have paired end data as that matches our own experiment, so that can be built in as an if statement.

At this point, we simply integrate with our loop. We run kraken2, then bracken, then we remove all intermediary files and probably just save bracken output table. This should be possible from Dan's cluster account once he has a bracken conda environment, provided bracken hasn't updated a bunch. All kraken2 code and databases are in PAS1479. 

This should create a job we can use to create an array, which we can then qalter to prevent everything from running at once.

```{r}
grab.uids <- read.csv("../data/tcga-gdc-manifest_2020-03-11.csv", stringsAsFactors = F)
tok <- read.table("~/Documents/gdc.txt", stringsAsFactors = F)[1,1]

# Write pbs submission file
fileOut<-file("/fs/scratch/PAS1460/exoTCC/batch/TCGA_kraken2-bracken/array-sub.pbs")

writeLines(c("#PBS -N exoTCC_TCGA-validate",
             "#PBS -l walltime=04:00:00",
             "#PBS -l nodes=1:ppn=20", # This may also need to be made greedier
             "#PBS -j oe",
             "#PBS -m abe",
             "#PBS -A PAS1460",
             "",
             #List our important info in a way that can be indexed
             paste0("uuids=('", paste(grab.uids$id, collapse = "' '"), "')"),
             paste0("bnams=('", paste(grab.uids$filename, collapse = "' '"), "')"),
             "",
             "module load R",
             "",
             #BAM download and test - I'm assuming DS saves token in home directory here
             paste0('rstring="GenomicDataCommons::gdcdata(\'${uuids[$PBS_ARRAYID]}\', progress=FALSE, token = \'', tok,'\')"'),
             'Rscript -e \"GenomicDataCommons::gdc_set_cache(\'$TMPDIR\')\" -e \"$rstring\"',
             "",
             "module load python/3.6-conda5.2",
             "module load bam2fastq",
             "module load samtools",
             "",
             "testpaired=$(samtools view -c -f 1 $TMPDIR/${uuids[$PBS_ARRAYID]}/${bnams[$PBS_ARRAYID]})",
             "if [ $testpaired -eq 0 ];then rm $TMPDIR/${uuids[$PBS_ARRAYID]}/${bnams[$PBS_ARRAYID]};fi", 
             "",
             
             # Create our working direcory
             "mkdir $TMPDIR/intermediate/",
             "mkdir $TMPDIR/brackout",
             
             # Manipulate to fastqs.
             "samtools sort -n --output-fmt BAM -o $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}.qsort $TMPDIR/${uuids[$PBS_ARRAYID]}/${bnams[$PBS_ARRAYID]}",                     
             "bam2fastq -o $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}#.fastq $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}.qsort",
             "",
             
             # Run kraken2/bracken
             "cd $TMPDIR/intermediate/",
             "ls",
             "/fs/scratch/PAS1479/src/kraken2-src/kraken2/kraken2 --db /fs/scratch/PAS1479/databases/kraken2-db --threads 20 --minimum-base-quality 20 --report ${uuids[$PBS_ARRAYID]}.txt --confidence 0.1 --paired $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}_1.fastq $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}_2.fastq",
             "",
             "source activate kraken2",
             "bracken -d /fs/scratch/PAS1479/databases/kraken2-db -l S -i ${uuids[$PBS_ARRAYID]}.txt -o ../brackout/${uuids[$PBS_ARRAYID]}.txt",
             "",
             
             # save desired files.
             "cp $TMPDIR/brackout/${uuids[$PBS_ARRAYID]}.txt /fs/scratch/PAS1460/exoTCC/brackout/TCGA/"
),

fileOut
)

```