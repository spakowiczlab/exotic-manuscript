---
title: "gdc-manifest-generation"
author: "Rebecca Hoyd"
date: "February 27, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(GenomicDataCommons)
```

# Look for variables to filter

```{r, eval=F}
avail.data <- available_fields(files())
length(avail.data)

```

```{r}
test[grep("file_id", test)]
```


```{r, eval=F}
avail.data[grep("project", avail.data)]
```

```{r, eval=F}
avail.data[grep("tumor", avail.data)]
```

# Query the files, find desired filters

```{r, eval=F}
# Get the files from TCGA only that are of the data type "aligned reads"
tcga.bams <- GenomicDataCommons::files(legacy = F) %>%
  filter(type == "aligned_reads") %>%
  # filter(experimental_strategy == "RNA-Seq") %>% # This line breaks everything after it but the results, but I want                                                         to add it back later
  filter(cases.project.program.name =='TCGA')

# Use facet + aggregations to count how many files are in each value of a given variable
tcga.bams %>%
  # facet(c("cases.project.name", "cases.project.project_id")) %>% 
  facet(c("cases.project.project_id")) %>% 
  aggregations()
```

```{r, eval=F}
tcga.bams %>%
  # facet(c("cases.project.name", "cases.project.project_id")) %>% 
  facet(c("experimental_strategy")) %>% 
  aggregations()

tcga.bams %>%
  # facet(c("cases.project.name", "cases.project.project_id")) %>% 
  facet(c('cases.samples.sample_type')) %>% 
  aggregations()
```

# Get the list of files, limited to desired cancers + made into manifest

```{r, eval=F}
grab.uids.1 <- list()
for(c in c("TCGA-LUAD", "TCGA-COAD", "TCGA-READ")){
  grab.uids.1[[c]] <- tcga.bams %>%
  filter(cases.samples.sample_type == "primary tumor") %>%
  filter(experimental_strategy == "RNA-Seq") %>%
  filter(cases.project.project_id == c) %>% 
  manifest() %>%
  dplyr::mutate(cancer = c,
                source = "tumor")
}
grab.uids.1 <- dplyr::bind_rows(grab.uids.1)
nrow(grab.uids.1)

grab.uids.2 <- list()
for(c in c("TCGA-LUAD", "TCGA-COAD", "TCGA-READ")){
  grab.uids.2[[c]] <- tcga.bams %>%
  filter(cases.samples.sample_type == "solid tissue normal") %>%
  filter(experimental_strategy == "RNA-Seq") %>%
  filter(cases.project.project_id == c) %>% 
  manifest() %>%
  dplyr::mutate(cancer = c,
                source = "solid.tissue.normal")
}
grab.uids.2 <- dplyr::bind_rows(grab.uids.2)
nrow(grab.uids.2)

grab.uids <- dplyr::bind_rows(grab.uids.1, grab.uids.2)
```

```{r}
grab.clinid <- GenomicDataCommons::cases(legacy = F) %>%
  GenomicDataCommons::select(c(default_fields("cases"), "files.file_id")) %>%
  filter(files.type == "aligned_reads") %>%
  filter(project.program.name =='TCGA') %>%
  filter(samples.sample_type == "primary tumor") %>%
  # filter(files.experimental_strategy == "RNA-Seq") %>%
  filter(project.project_id == "TCGA-COAD") %>%
  response_all()

for(cid in names(grab.clinid$results$files)){
  grab.clinid$results$files[[cid]] <- grab.clinid$results$files[[cid]] %>%
    dplyr::mutate(case_id = cid)
}
checkfilepres <- dplyr::bind_rows(grab.clinid$results$files)
any(checkfilepres$file_id %in% grab.uids$id)
```

```{r}
# We need to keep the manifest, as it has all the metadata of where the samples are from, and we should date it because TCGA can change as more studies are updated
# write.csv(grab.uids, "../data/tcga-gdc-manifest_2020-03-11.csv", row.names = F)
```

# Notes on next steps

The following function downloads files based on the uuids provided, and automatically throws them in a cache. This is the step that requires Dan's token.

```{r, eval = F}
fnames = gdcdata(grab.uids$id[1],progress=FALSE, token = tok)
```

```{r}
grab.uids <- read.csv("../data/tcga-gdc-manifest_2020-03-11.csv", stringsAsFactors = F)
tok <- read.table("~/Documents/gdc.txt", stringsAsFactors = F)[1,1]

# Write pbs submission file
fileOut<-file("/fs/scratch/PAS1460/exoTCC/batch/TCGA_kraken2-bracken/array-sub.pbs")

writeLines(c("#PBS -N exoTCC_TCGA-validate",
             "#PBS -l walltime=04:00:00",
             "#PBS -l nodes=1:ppn=20", # This may also need to be made greedier
             "#PBS -j oe",
             "#PBS -m abe",
             "#PBS -A PAS1460",
             "",
             #List our important info in a way that can be indexed
             paste0("uuids=('", paste(grab.uids$id, collapse = "' '"), "')"),
             paste0("bnams=('", paste(grab.uids$filename, collapse = "' '"), "')"),
             "",
             "module load R",
             "",
             #BAM download and test - I'm assuming DS saves token in home directory here
             paste0('rstring="GenomicDataCommons::gdcdata(\'${uuids[$PBS_ARRAYID]}\', progress=FALSE, token = \'', tok,'\')"'),
             'Rscript -e \"GenomicDataCommons::gdc_set_cache(\'$TMPDIR\')\" -e \"$rstring\"',
             "",
             "module load python/3.6-conda5.2",
             "module load bam2fastq",
             "module load samtools",
             "",
             "testpaired=$(samtools view -c -f 1 $TMPDIR/${uuids[$PBS_ARRAYID]}/${bnams[$PBS_ARRAYID]})",
             "if [ $testpaired -eq 0 ];then rm $TMPDIR/${uuids[$PBS_ARRAYID]}/${bnams[$PBS_ARRAYID]};fi", 
             "",
             
             # Create our working direcory
             "mkdir $TMPDIR/intermediate/",
             "mkdir $TMPDIR/brackout",
             
             # Manipulate to fastqs.
             "samtools sort -n --output-fmt BAM -o $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}.qsort $TMPDIR/${uuids[$PBS_ARRAYID]}/${bnams[$PBS_ARRAYID]}",                     
             "bam2fastq -o $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}#.fastq $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}.qsort",
             "",
             
             # Run kraken2/bracken
             "cd $TMPDIR/intermediate/",
             "ls",
             "/fs/scratch/PAS1479/src/kraken2-src/kraken2/kraken2 --db /fs/scratch/PAS1479/databases/kraken2-db --threads 20 --minimum-base-quality 20 --report ${uuids[$PBS_ARRAYID]}.txt --confidence 0.1 --paired $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}_1.fastq $TMPDIR/intermediate/${uuids[$PBS_ARRAYID]}_2.fastq",
             "",
             "source activate kraken2",
             "bracken -d /fs/scratch/PAS1479/databases/kraken2-db -l S -i ${uuids[$PBS_ARRAYID]}.txt -o ../brackout/${uuids[$PBS_ARRAYID]}.txt",
             "",
             
             # save desired files.
             "cp $TMPDIR/brackout/${uuids[$PBS_ARRAYID]}.txt /fs/scratch/PAS1460/exoTCC/brackout/TCGA/"
),

fileOut
)

```

# Pull clinical data 
```{r}
grab.clinid <- GenomicDataCommons::cases(legacy = F) %>%
  GenomicDataCommons::select(c(default_fields("cases"), "files.file_id")) %>%
  filter(files.type == "aligned_reads") %>%
  filter(project.program.name =='TCGA') %>%
  filter(samples.sample_type %in% c("primary tumor", "solid tissue normal")) %>%
  # filter(files.experimental_strategy == "RNA-Seq") %>%
  filter(project.project_id %in% c("TCGA-LUAD", "TCGA-COAD", "TCGA-READ")) %>%
  response_all()

for(cid in names(grab.clinid$results$files)){
  grab.clinid$results$files[[cid]] <- grab.clinid$results$files[[cid]] %>%
    dplyr::mutate(case_id = cid)
}
checkfilepres <- dplyr::bind_rows(grab.clinid$results$files)
all(grab.uids$id %in% checkfilepres$file_id)
```

```{r}
file.case <- checkfilepres %>%
  dplyr::filter(file_id %in% grab.uids$id)
choosecases <- unique(file.case$case_id)

addtranslate <- file.case %>%
  dplyr::mutate(id = file_id) %>%
  dplyr::left_join(grab.uids) %>%
  dplyr::select(file_id, case_id, cancer, source)

grab.clindat <- gdc_clinical(choosecases)
clindat.form <- Reduce(function(dtf1,dtf2) dplyr::full_join(dtf1,dtf2,by="case_id"),
                       grab.clindat) %>%
  dplyr::left_join(addtranslate)
# write.csv(clindat.form, "/fs/scratch/PAS1479/data/TCGA-clnical.csv", row.names = F)
```

