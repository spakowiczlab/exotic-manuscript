---
title: "H2O machine learning"
author: "Rebecca Hoyd"
date: "2/21/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# library(caret)
library(tidyverse)
library(h2o)
# library(lares)

```

# Load data

```{r}
datadir <- "/fs/ess/PAS1695/projects/exotic/data/drake-output/2022-03-08"

tcc.exora.taxonomy <- readRDS(file.path(datadir, "tcc.exora.taxonomy.RDS"))
tcc.clin <- read.csv("/fs/ess/PAS1695/projects/exotic/data/2020-02-19_clinical_aggregated.csv")
```

# Functions

```{r}
exoRAtowide <- function(data, taxlev){
  tmp <- data
  tmp$Taxa <- tmp[[taxlev]]
  tmp.wide<- tmp %>%
    dplyr::filter(!is.na(Taxa)) %>%
    group_by(sample, Taxa) %>%
    summarise(ra = sum(exo.ra, na.rm = T)) %>%
    spread(key = "Taxa", value = "ra")
  
  tmp.wide[is.na(tmp.wide)] <- 0
  return(tmp.wide)
}

exoToDF <- function(taxalevels = c("domain", "kingdom", "phylum", "class", 
                                    "order", "family", "genus", "species"), 
                     data){
  w.ls <- lapply(taxalevels, function(x) exoRAtowide(data, x))
  w.df <- reduce(w.ls, function(x,y) left_join(x,y)) 
  return(w.df)
}
```


# Formatting

```{r wide microbe data}
tcc.w <- exoRAtowide(tcc.exora.taxonomy, "species")

tcc.modin <- tcc.clin %>%
  mutate(sample = RNA.SL.ID,
         Cancer = as.factor(Cancer)) %>%
  select(sample, Cancer) %>%
  inner_join(tcc.w) %>%
  select(-sample)
```
# Old 

## Generate

```{r, eval=FALSE}
r <- h2o_automl(tcc.modin, 
                y = Cancer, 
                max_models = 40, 
                impute = FALSE, 
                target = "True",
                split = 0.7, 
                seed = 12345, 
                start_clean = TRUE)

r

```

```{r, eval=FALSE}
r$model@algorithm
r$model@parameters
```

## Remake specific model

```{r, eval=FALSE}
datset.test <- r$datasets$test[,1:4093]
datset.all <- r$datasets$global[,1:4093]
datset.train <- setdiff(datset.all,datset.test) %>%
  mutate(Cancer = as.factor(Cancer)) %>%
  select(Cancer, everything())
datset.train.labs <- datset.train$Cancer

# datset.train <- datset.train %>%
#   select(-Cancer)

datset.test.pred <- datset.test %>%
  select(-Cancer)
```

```{r, eval=FALSE}
set.seed(12351)
# gbm.mod <- train(data = datset.train,
#                  formula = Cancer ~ .,
#                  x = datset.train,
#                  y = datset.train.labs,
#                  method = "gbm",
#                # col_sample_rate = 0.8,
#                # col_sample_per_tree =0.8,
#                # sample_rate = 0.8,
#                n.trees = 19,
#                interaction.depth = 8,
#                shrinkage = 0.1,
#                distribution = "multinomial")

gbm.carfit <- train(datset.train[,-1], datset.train$Cancer,
                    method = "gbm",
                    tuneGrid=expand.grid(
                      n.trees=19,
                      interaction.depth=8,
                      shrinkage=.1,
                       n.minobsinnode=1
                    ),
                    distribution = "multinomial")

car.pred <- predict(gbm.carfit, datset.test[,-1])
print(gbm.carfit)
pROC::multiclass.roc(as.numeric(datset.test$Cancer), as.numeric(car.pred))
```

```{r, eval=FALSE}
library(gbm)
caret.imp <- varImp(gbm.carfit, scale = F) $importance
caret.imp
write.csv(caret.imp, "../data/gbm_variable-importance.csv")
```

```{r, eval=FALSE}
# summary(
#   gbm.mod, 
#   cBars = 10,
#   method = relative.influence, # also can use permutation.test.gbm
#   las = 2
#   )
```

```{r, eval=FALSE}
# gbm.pred <- predict.gbm(gbm.mod, datset.test, n.trees = gbm.mod$n.trees,
#                         type = "response")
# 
# gbm.bestpred <- gbm.pred %>%
#   as.data.frame() %>%
#   rownames_to_column(var = "idord") %>%
#   gather(-idord, key = "cancer", value = "prob") %>%
#   group_by(idord) %>%
#   mutate(maxprob = max(prob)) %>%
#   ungroup() %>%
#   filter(prob == maxprob) %>%
#   arrange(idord) %>%
#   mutate(Cancer = gsub("\\.19", "", cancer))
```

```{r, eval=FALSE}
# library(pROC)
# multiclass.roc(as.numeric(as.factor(datset.test$Cancer)), as.numeric(as.factor(gbm.bestpred$Cancer)))
```

## Binarize

```{r, eval=FALSE}
datset.all.bin <- datset.train %>%
  mutate(Cancer = ifelse(Cancer == "GI", "1","0")) %>%
  select(Cancer, everything())
datset.test.bin <- datset.test %>%
  mutate(Cancer = ifelse(Cancer == "GI", "1", "0")) %>%
  select(Cancer, everything())

set.seed(12351)
ctrl <- trainControl(savePredictions = T)
gbm.carfit.bin <- train(datset.all.bin[,-1], datset.all.bin$Cancer,
                    method = "gbm",
                    tuneGrid=expand.grid(
                      n.trees=19,
                      interaction.depth=8,
                      shrinkage=.1,
                       n.minobsinnode=1
                    ),
                    distribution = "bernoulli",
                    trControl = ctrl)
```

```{r, eval=FALSE}
# indices <- gbm.carfit.bin$pred$Resample == "Resample25"
# png("../figures/roc_gbm-bin.png")
# pROC::plot.roc(as.numeric(gbm.carfit.bin$pred$obs[indices]),
#                as.numeric(gbm.carfit.bin$pred$pred[indices]))
# dev.off()
```

```{r, eval=FALSE}
bin.preds <- predict(gbm.carfit.bin, datset.test.bin[,-1], type = "prob")
pROC::roc(as.numeric(datset.test.bin$Cancer), bin.preds$`1`)

png("../figures/roc_gbm-bin.png")
pROC::plot.roc(as.numeric(datset.test.bin$Cancer), bin.preds$`1`)
dev.off()
```

# New, following AWS tutorial

http://h2o-release.s3.amazonaws.com/h2o/master/1292/docs-website/tutorial/rtutorial.html

## Generate local h2o object
```{r}
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE)
```

## import R data

```{r}
set.seed(112358)
trainsamps <- sort(sample(nrow(tcc.modin), .8*nrow(tcc.modin)))
tcc.train <- tcc.modin[trainsamps,]
tcc.test <- tcc.modin[-trainsamps,]
modin.h2o <- as.h2o(tcc.train)
modval.h2o <- as.h2o(tcc.test)
```

## Run gbm

The tutorial uses argument names that don't match the current version of the package. I'm going to assume the defaults are reasonable for the first run, if that's awful we'll try to use the arguments from the auto ml.

```{r}
h2o.gbm(y = "Cancer", training_frame = modin.h2o, validation_frame = modval.h2o,
        distribution= "multinomial", seed = 112358)
```

```{r}
h2o.gbm(y = "Cancer", training_frame = modin.h2o, validation_frame = modval.h2o,
        distribution= "multinomial",ntrees = 19, seed = 12345,
        col_sample_rate = 0.8,sample_rate=0.8)
```